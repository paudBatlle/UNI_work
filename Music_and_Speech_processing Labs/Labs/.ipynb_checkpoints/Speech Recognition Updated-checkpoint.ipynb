{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will use Python to work with a simple speech recognition system.\n",
    "Unzip Lab11.rar file and you will find:\n",
    "\n",
    "* Vowel recordings: in folder: /Lab11/DB/DBvocals/*.wav\n",
    "* where part of these recordings will be used to train the vowel\n",
    "speech recognition system. The other part is the one that we will\n",
    "use to classify and evaluate the accuracy of the system based on\n",
    "the correct percentage.\n",
    "* Guide files:\n",
    "* /Lab11/DBvocals_train_list_times.txt\n",
    "* /Lab11/DBvocals_test_list_times.txt\n",
    "* To know what recordings we will use as a training and as a test we\n",
    "have these guide files.\n",
    "* Each file contains the path of some * .wav files as well as 10 time\n",
    "stamps: the start and end times of each of the 5 vowels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install the environment using \n",
    "    pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "\n",
    "A. Set up\n",
    "Have a look at the following code to check how it works. You can execute the code and debug to see what the variables contain:\n",
    "\n",
    "accuracy = lab11('DBvocals_train_list_times.txt', 'DBvocals_test_list_times.txt', 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataset, nc, plot_data):\n",
    "    data_mfcc = np.array([])\n",
    "    data_labels = np.array([])\n",
    "    for audio in range(len(dataset)):\n",
    "        vowel_times = dataset[audio][1:];\n",
    "        y, sr = librosa.load(dataset[audio][0],\n",
    "                            sr=44100)\n",
    "        # Use parameters : n_fft = 0.025 seconds, hop_length = 0.010\n",
    "        mfcc_win = 0.025\n",
    "        mfcc_hop = 0.010\n",
    "        mfcc = librosa.feature.mfcc(y=y, \n",
    "                                    sr=sr,\n",
    "                                    hop_length = 441,\n",
    "                                    n_fft = 1103,\n",
    "                                    n_mfcc=nc)\n",
    "\n",
    "        labels = np.zeros(np.shape(mfcc))[1]\n",
    "        tt_mfcc  = mfcc_win/2 + mfcc_hop*np.arange(np.shape(mfcc)[1]);\n",
    "        for vowel_ind in np.arange(1,6):\n",
    "            start_sample = np.argmin(abs(tt_mfcc-float(vowel_times[(vowel_ind-1)*2])))\n",
    "            end_sample = np.argmin(abs(tt_mfcc-float(vowel_times[(vowel_ind-1)*2 + 1])))\n",
    "            labels[start_sample:end_sample] = vowel_ind;\n",
    "        \n",
    "        data_mfcc  = np.concatenate((data_mfcc, mfcc), axis = 1) if data_mfcc.size else mfcc\n",
    "        \n",
    "        data_labels = np.append(data_labels, labels)\n",
    "        if plot_data:\n",
    "            tt = np.arange(len(y))/sr\n",
    "            plt.plot(tt,y)\n",
    "            plt.plot(tt_mfcc, max(abs(y))/max(labels)*labels, 'r');\n",
    "            plt.show()\n",
    "        \n",
    "    return (data_mfcc, data_labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('./Lab11/DBvocals_train_list_times.txt', dtype = 'unicode')\n",
    "test_data = np.loadtxt('./Lab11/DBvocals_test_list_times.txt', dtype = 'unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to run the above function with the train and test data. Test the function using\n",
    "# process_data(train_data, 13, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P1. Open the input txt file DBvocals_test_list_times.txt and make sure you\n",
    "understand their content. To which vowel do times 4.28 and 4.74\n",
    "correspond to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P2. By debugging the code, plot the data in the\n",
    "train_labels variable. What does it correspond to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P3. By debugging the code with breakpoints, check the dimensions of\n",
    "train_mfcc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Classification with “nearest neighbours”\n",
    "\n",
    "A simple method for classification is called nearest neighbors. Starting from 2\n",
    "data set, one of them will serve as a reference (training set) to be able to classify\n",
    "the other one (test set). The method assigns to the unknown data the closest\n",
    "class of the training group based on a measure of distance between vectors.\n",
    "For each data point in the test set to be classified (example: vector \"a\" of N = 13\n",
    "MFCC coefficients), we will calculate the Euclidean distance to each element \"b\"\n",
    "of the training set. Remember not to compute the distance to silence vectors,\n",
    "only to vowel MFCC vectors. Thus, in our case of vectors of 13 components, the\n",
    "distance between 2 vectors \"a\" and \"b\" would be:\n",
    "\\begin{equation}\n",
    "d = \\sqrt{(a_{1}-b_{1})^2 + (a_{2}-b_{2})^2 + ... + (a_{N}-b_{N})^2}  with N = 13\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterion of \"nearest neighbors\" to assign a class is that the observation to\n",
    "classify will be assigned the same class of the closest (minimum distance d)\n",
    "element from the training set. In general, we will use the data of train recordings\n",
    "for the training and the test set to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_labels = nearest_neighbours(train_labels, train_mfcc, test_labels, test_mfcc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P4. Implement the nearest_neighbours function. How many ‘for’ loops does\n",
    "your implementation need in order to process all the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this case, just try to understand the algorithm how it works and how many for loops you would need to implement it. For this exercise, you can use KNeighborsClassifier from sklean library with K=5. To use it:\n",
    "* knn = KNeighborsClassifier(n_neighbors = (), metric='euclidean')\n",
    "* knn.fit((training data), (training labels)\n",
    "* (prediction labels)= knn.predict((test data))\n",
    "\n",
    "* Note: You might have to use numpy.transpose with training data and test data to match the dimensions with the corresponging labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P5. Which set should you first iterate to build the nearest neighbours\n",
    "classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the classification accuracy, we calculate the percentage of well-\n",
    "qualified frames. That is, only for those frames that correspond to a vowel, we\n",
    "compare the reference (test_labels) to our classification (class_labels).\n",
    "Implement the code to compute the precision (accuracy) of the test frames\n",
    "classification (only taking into account those labeled as a vowel, not the silence).\n",
    "accuracy = ... (it is a percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, use numpy.where function to filter labels that are set to 0. The vowel labels are represented using 1 to 5. Once you have the filtered labels, use the resulting indexes to get the corresponding data points. Remember to filter the testing data labels also for predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Classification with different configurations\n",
    "\n",
    "Run the code with the training file that accompanies the lab. As a test, use this\n",
    "same training file. Use nc = 13.\n",
    "\n",
    "P6. Which accuracy do you get when classifying the train set (percentage)?\n",
    "Run the code with the training and test files that accompany the lab. Use nc = 13\n",
    "MFCCs.\n",
    "\n",
    "P7. Which accuracy do get when classifying the test set?\n",
    "\n",
    "P8. Which accuracy do you get when classifying the test set with 3\n",
    "coefficients?\n",
    "\n",
    "P9. Which accuracy do you get when classifying the test set using only the\n",
    "first 2 training files as reference and 13 coeffients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
